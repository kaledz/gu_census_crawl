{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c39acd96-cbbf-497f-ae6d-fa327d3e7987",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Wet File Data Extraction**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c15fd1f0-5a1a-4a07-b6f9-829152f1a14e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85bee9fd-c83f-44e6-bffd-c896c4d2d1c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import boto3\n",
    "import botocore\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52b43ba1-7453-499a-8eda-83194ca68631",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Connect to Boto3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94f77efa-cc51-46b5-98ba-9be74c96e12a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.1 Set Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71753b31-0137-4637-9b03-fd4591ac43b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "aws_access_key_id = dbutils.secrets.get(scope='aws_cc', key='aws_access_key_id')\n",
    "aws_secret_access_key = dbutils.secrets.get(scope='aws_cc', key='aws_secret_access_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6c9b7b0-70b1-44df-9b82-91854363519d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.2 Intialize boto3 client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90566ef5-b594-4c43-887e-d70e7dcb3560",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Optional: build client once (faster)\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    region_name=\"us-east-1\",\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a20ff338-1648-4525-9e58-e6e7063576ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 3.1.2 Set to python list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49fba408-3508-4a65-a2bb-a1a470dc2a38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "key_list = df_all_crawls_samples['Key'].tolist()\n",
    "\n",
    "print(key_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a252a2c7-8a77-424f-98c9-ed44b288b376",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1300efb4-34d9-414f-879b-5cb840587ca1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.1 Extract CC Wet file\n",
    "- Extracrts the random sample text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b44bfa2c-44f5-4e6a-ac26-219ec8cc9daa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_bucket = \"commoncrawl\"\n",
    "destination_bucket = 'mydbxbucketpractice'\n",
    "\n",
    "for source_key in key_list:\n",
    "    destination_key = (\n",
    "        'common_crawl/wet_files/' +\n",
    "        source_key.split(\"/\")[-1]\n",
    "    )\n",
    "    local_filename = '/tmp/' + source_key.split(\"/\")[-1]\n",
    "    \n",
    "    s3.download_file(source_bucket, source_key, local_filename)\n",
    "    s3.upload_file(local_filename, destination_bucket, destination_key)\n",
    "    os.remove(local_filename)\n",
    "    \n",
    "    print(\n",
    "        f\"Copied s3://{source_bucket}/{source_key} to \"\n",
    "        f\"s3://{destination_bucket}/{destination_key}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "587cf290-32a0-49da-840a-c3cbd99eb6f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.2. View raw file as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26f38e38-dfc7-410b-9a5a-4688ee7fd7aa",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1757637738989}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, from_json\n",
    "\n",
    "file_paths = [f\"s3://{destination_bucket}/common_crawl/wet_files/{file.name}\" for file in dbutils.fs.ls(f\"s3://{destination_bucket}/common_crawl/wet_files/\")]\n",
    "\n",
    "df_combined = spark.read.text(file_paths)\n",
    "\n",
    "# Filter rows that look like JSON objects (start with '{' and end with '}')\n",
    "df_json = df_combined.filter(\n",
    "    (col(\"value\").startswith(\"{\")) & (col(\"value\").endswith(\"}\"))\n",
    ")\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"Container\", StructType([\n",
    "        StructField(\"Filename\", StringType(), True),\n",
    "        StructField(\"Compressed\", BooleanType(), True),\n",
    "        StructField(\"Offset\", StringType(), True),\n",
    "        StructField(\"Gzip-Metadata\", StructType([\n",
    "            StructField(\"Deflate-Length\", StringType(), True),\n",
    "            StructField(\"Header-Length\", StringType(), True),\n",
    "            StructField(\"Footer-Length\", StringType(), True),\n",
    "            StructField(\"Inflated-CRC\", StringType(), True),\n",
    "            StructField(\"Inflated-Length\", StringType(), True)\n",
    "        ]), True)\n",
    "    ]), True),\n",
    "    StructField(\"Envelope\", StructType([\n",
    "        StructField(\"Payload-Metadata\", StructType([\n",
    "            StructField(\"Actual-Content-Length\", StringType(), True),\n",
    "            StructField(\"Trailing-Slop-Length\", StringType(), True),\n",
    "            StructField(\"Block-Digest\", StringType(), True),\n",
    "            StructField(\"Headers-Corrupt\", BooleanType(), True),\n",
    "            StructField(\"Actual-Content-Type\", StringType(), True),\n",
    "            StructField(\"WARC-Info-Metadata\", StructType([\n",
    "                StructField(\"isPartOf\", StringType(), True),\n",
    "                StructField(\"publisher\", StringType(), True),\n",
    "                StructField(\"description\", StringType(), True),\n",
    "                StructField(\"operator\", StringType(), True),\n",
    "                StructField(\"hostname\", StringType(), True),\n",
    "                StructField(\"software\", StringType(), True),\n",
    "                StructField(\"robots\", StringType(), True),\n",
    "                StructField(\"format\", StringType(), True)\n",
    "            ]), True)\n",
    "        ]), True),\n",
    "        StructField(\"Format\", StringType(), True),\n",
    "        StructField(\"WARC-Header-Length\", StringType(), True),\n",
    "        StructField(\"WARC-Header-Metadata\", StructType([\n",
    "            StructField(\"WARC-Type\", StringType(), True),\n",
    "            StructField(\"WARC-Date\", StringType(), True),\n",
    "            StructField(\"WARC-Record-ID\", StringType(), True),\n",
    "            StructField(\"Content-Length\", StringType(), True),\n",
    "            StructField(\"Content-Type\", StringType(), True),\n",
    "            StructField(\"WARC-Filename\", StringType(), True)\n",
    "        ]), True)\n",
    "    ]), True)\n",
    "])\n",
    "\n",
    "# Parse the JSON strings into a DataFrame using the defined schema\n",
    "df_flat = df_json.withColumn(\"parsed_value\", from_json(col(\"value\"), schema)).select(\"parsed_value.*\")\n",
    "\n",
    "# Flatten the nested structure further\n",
    "df_flattened = df_flat.select(\n",
    "    col(\"Container.Filename\").alias(\"Container_Filename\"),\n",
    "    col(\"Container.Compressed\").alias(\"Container_Compressed\"),\n",
    "    col(\"Container.Offset\").alias(\"Container_Offset\"),\n",
    "    col(\"Container.Gzip-Metadata.Deflate-Length\").alias(\"Container_Gzip_Metadata_Deflate_Length\"),\n",
    "    col(\"Container.Gzip-Metadata.Header-Length\").alias(\"Container_Gzip_Metadata_Header_Length\"),\n",
    "    col(\"Container.Gzip-Metadata.Footer-Length\").alias(\"Container_Gzip_Metadata_Footer_Length\"),\n",
    "    col(\"Container.Gzip-Metadata.Inflated-CRC\").alias(\"Container_Gzip_Metadata_Inflated_CRC\"),\n",
    "    col(\"Container.Gzip-Metadata.Inflated-Length\").alias(\"Container_Gzip_Metadata_Inflated_Length\"),\n",
    "    col(\"Envelope.Payload-Metadata.Actual-Content-Length\").alias(\"Envelope_Payload_Metadata_Actual_Content_Length\"),\n",
    "    col(\"Envelope.Payload-Metadata.Trailing-Slop-Length\").alias(\"Envelope_Payload_Metadata_Trailing_Slop_Length\"),\n",
    "    col(\"Envelope.Payload-Metadata.Block-Digest\").alias(\"Envelope_Payload_Metadata_Block_Digest\"),\n",
    "    col(\"Envelope.Payload-Metadata.Headers-Corrupt\").alias(\"Envelope_Payload_Metadata_Headers_Corrupt\"),\n",
    "    col(\"Envelope.Payload-Metadata.Actual-Content-Type\").alias(\"Envelope_Payload_Metadata_Actual_Content_Type\"),\n",
    "    col(\"Envelope.Payload-Metadata.WARC-Info-Metadata.isPartOf\").alias(\"Envelope_Payload_Metadata_WARC_Info_Metadata_isPartOf\"),\n",
    "    col(\"Envelope.Payload-Metadata.WARC-Info-Metadata.publisher\").alias(\"Envelope_Payload_Metadata_WARC_Info_Metadata_publisher\"),\n",
    "    col(\"Envelope.Payload-Metadata.WARC-Info-Metadata.description\").alias(\"Envelope_Payload_Metadata_WARC_Info_Metadata_description\"),\n",
    "    col(\"Envelope.Payload-Metadata.WARC-Info-Metadata.operator\").alias(\"Envelope_Payload_Metadata_WARC_Info_Metadata_operator\"),\n",
    "    col(\"Envelope.Payload-Metadata.WARC-Info-Metadata.hostname\").alias(\"Envelope_Payload_Metadata_WARC_Info_Metadata_hostname\"),\n",
    "    col(\"Envelope.Payload-Metadata.WARC-Info-Metadata.software\").alias(\"Envelope_Payload_Metadata_WARC_Info_Metadata_software\"),\n",
    "    col(\"Envelope.Payload-Metadata.WARC-Info-Metadata.robots\").alias(\"Envelope_Payload_Metadata_WARC_Info_Metadata_robots\"),\n",
    "    col(\"Envelope.Payload-Metadata.WARC-Info-Metadata.format\").alias(\"Envelope_Payload_Metadata_WARC_Info_Metadata_format\"),\n",
    "    col(\"Envelope.Format\").alias(\"Envelope_Format\"),\n",
    "    col(\"Envelope.WARC-Header-Length\").alias(\"Envelope_WARC_Header_Length\"),\n",
    "    col(\"Envelope.WARC-Header-Metadata.WARC-Type\").alias(\"Envelope_WARC_Header_Metadata_WARC_Type\"),\n",
    "    col(\"Envelope.WARC-Header-Metadata.WARC-Date\").alias(\"Envelope_WARC_Header_Metadata_WARC_Date\"),\n",
    "    col(\"Envelope.WARC-Header-Metadata.WARC-Record-ID\").alias(\"Envelope_WARC_Header_Metadata_WARC_Record_ID\"),\n",
    "    col(\"Envelope.WARC-Header-Metadata.Content-Length\").alias(\"Envelope_WARC_Header_Metadata_Content_Length\"),\n",
    "    col(\"Envelope.WARC-Header-Metadata.Content-Type\").alias(\"Envelope_WARC_Header_Metadata_Content_Type\"),\n",
    "    col(\"Envelope.WARC-Header-Metadata.WARC-Filename\").alias(\"Envelope_WARC_Header_Metadata_WARC_Filename\")\n",
    ")\n",
    "\n",
    "display(df_flattened)\n",
    "\n",
    "total = df_flattened.count()\n",
    "print(f\"total: {total:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03651ae6-8a0b-4598-a394-836bf9726d3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "180a9db1-c7ef-448c-a090-559bf8668c06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 4.2.1 Drop Files if needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb927836-4953-418a-be93-96922f066812",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop all files from the directory\n",
    "# for file in dbutils.fs.ls(f\"s3://{destination_bucket}/common_crawl/wet_files/\"):\n",
    "    # dbutils.fs.rm(file.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf019db5-cdea-4a3f-b5d4-9de74194a985",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.3. Text transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfeeef80-c2c2-44ab-bfd3-7246ceac871a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Tokenize the text using RegexTokenizer\n",
    "regex_tokenizer = RegexTokenizer(inputCol=\"value\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "df_tokenized = regex_tokenizer.transform(df_combined)\n",
    "\n",
    "# Use StopWordsRemover to filter out non-English words\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "df_filtered = remover.transform(df_tokenized)\n",
    "\n",
    "# Combine the filtered words back into a single string\n",
    "df_combined_filtered = df_filtered.withColumn(\n",
    "    \"filtered_text\", \n",
    "    concat_ws(\" \", col(\"filtered_words\"))\n",
    ")\n",
    "\n",
    "# Select the relevant columns\n",
    "df_final = df_combined_filtered.select(\"filtered_text\").distinct()\n",
    "\n",
    "display(df_final)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) wat_files_extraction",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
