{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c39acd96-cbbf-497f-ae6d-fa327d3e7987",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Wet File Data Extraction\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c15fd1f0-5a1a-4a07-b6f9-829152f1a14e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85bee9fd-c83f-44e6-bffd-c896c4d2d1c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import col, lower, when, sum as spark_sum, collect_list, concat_ws, udf, explode\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType\n",
    "import re\n",
    "import boto3\n",
    "import botocore\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message='.*No Partition Defined for Window operation.*')\n",
    "\n",
    "import time\n",
    "\n",
    "time_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52b43ba1-7453-499a-8eda-83194ca68631",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Connect to Boto3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94f77efa-cc51-46b5-98ba-9be74c96e12a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.1 Set Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71753b31-0137-4637-9b03-fd4591ac43b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "aws_access_key_id = dbutils.secrets.get(scope='aws_cc', key='aws_access_key_id')\n",
    "aws_secret_access_key = dbutils.secrets.get(scope='aws_cc', key='aws_secret_access_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6c9b7b0-70b1-44df-9b82-91854363519d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.2 Intialize boto3 client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90566ef5-b594-4c43-887e-d70e7dcb3560",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Optional: build client once (faster)\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    region_name='us-east-1',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf019db5-cdea-4a3f-b5d4-9de74194a985",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Text transformation & Basic Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c82ec939-e50f-4161-8fb9-e3acdcee55c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read raw WET file\n",
    "df = spark.read.text(\n",
    "    's3://mydbxbucketpractice/common_crawl/wet_files/CC-MAIN-20220629054527-20220629084527-00796.warc.wet.gz'\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "340c280b-5831-45b1-a130-053d2b764edf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.1 Extract Header Function\n",
    "- Finds and extracts specific metadata fields from WET record headers\n",
    "- Example: Extracts the date, URL, or content type from the header section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f49ac36-30c7-40f9-b637-d7bdb6a3eb86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract header\n",
    "def extract_header(text, header_name):\n",
    "    \"\"\"\n",
    "    Extract a specific header value from WET headers.\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): The text containing headers\n",
    "    header_name (str): The name of the header to extract\n",
    "    \n",
    "    Returns:\n",
    "    str: The header value, or None if not found\n",
    "    \"\"\"\n",
    "    # Pattern to match header with optional quotes\n",
    "    pattern = rf'{re.escape(header_name)}:\\s*\"?([^\"\\n]+?)\"?\\s*$'\n",
    "    match = re.search(pattern, text, re.MULTILINE)\n",
    "    if match:\n",
    "        value = match.group(1).strip()\n",
    "        # Remove quotes if they're at the very start and end\n",
    "        if value.startswith('\"') and value.endswith('\"'):\n",
    "            value = value[1:-1]\n",
    "        return value\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af4ce93d-2543-4543-942a-fb2b056e283a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.2 Parse Single Record\n",
    "- Takes one complete WET record and breaks it into organized fields\n",
    "- Extracts: URL, date, language, content type, and the actual web page text\n",
    "- Returns a structured dictionary with all extracted information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac455cb6-4109-43fa-b1dc-80d44939fb1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to parse a single WET record\n",
    "def parse_single_wet_record(record_text):\n",
    "    \"\"\"\n",
    "    Parse a single WET record into structured fields.\n",
    "    \n",
    "    Parameters:\n",
    "    record_text (str): A complete WET record as text\n",
    "    \n",
    "    Returns:\n",
    "    dict: Parsed record with all fields\n",
    "    \"\"\"\n",
    "    if not record_text or not isinstance(record_text, str):\n",
    "        return None\n",
    "    \n",
    "    record = {\n",
    "        'Type': None,\n",
    "        'Target-URI': None,\n",
    "        'Date': None,\n",
    "        'Record-ID': None,\n",
    "        'Refers-To': None,\n",
    "        'Block-Digest': None,\n",
    "        'Identified-Content-Language': None,\n",
    "        'Content-Type': None,\n",
    "        'Content-Length': None,\n",
    "        'Content': None\n",
    "    }\n",
    "    \n",
    "    # Find Content-Length line and extract value\n",
    "    content_length_match = re.search(r'Content-Length:\\s*(\\d+)', record_text)\n",
    "    if not content_length_match:\n",
    "        return None\n",
    "    \n",
    "    record['Content-Length'] = content_length_match.group(1)\n",
    "    \n",
    "    # Split into headers and content\n",
    "    # Content starts after the first blank line following Content-Length\n",
    "    parts = re.split(r'\\nContent-Length:\\s*\\d+\\s*\\n\\n', record_text, maxsplit=1)\n",
    "    if len(parts) < 2:\n",
    "        return None\n",
    "    \n",
    "    headers = parts[0] + '\\nContent-Length: ' + record['Content-Length']\n",
    "    content = parts[1].strip()\n",
    "    \n",
    "    # Extract headers\n",
    "    record['Type'] = extract_header(headers, 'WARC-Type')\n",
    "    record['Target-URI'] = extract_header(headers, 'WARC-Target-URI')\n",
    "    record['Date'] = extract_header(headers, 'WARC-Date')\n",
    "    record['Record-ID'] = extract_header(headers, 'WARC-Record-ID')\n",
    "    record['Refers-To'] = extract_header(headers, 'WARC-Refers-To')\n",
    "    record['Block-Digest'] = extract_header(headers, 'WARC-Block-Digest')\n",
    "    record['Identified-Content-Language'] = extract_header(headers, 'WARC-Identified-Content-Language')\n",
    "    record['Content-Type'] = extract_header(headers, 'Content-Type')\n",
    "    record['Content'] = content\n",
    "    \n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0349e55-a5cb-478e-bdcc-9ca396361eea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.3 Convert to Dataframe\n",
    "- MAIN FUNCTION: Converts raw WET file into a clean, structured table\n",
    "- Process:\n",
    "  - Identifies where each web page record starts and ends in the file\n",
    "  - Groups all lines belonging to each record together\n",
    "  - Parses each record to extract metadata and content\n",
    "  - Removes system records (warcinfo) that aren't actual web pages\n",
    "- Input: Raw WET file loaded line-by-line\n",
    "- Output: Table with one row per web page, columns for URL, date, content, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ed4515b-e336-4b9e-b07a-88362dece0b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Main function that converts the text to columnar format\n",
    "def convert_wet_dataframe(df):\n",
    "    \"\"\"\n",
    "    Convert a Spark DataFrame (loaded via spark.read.text) containing WARC data \n",
    "    into columnar format.\n",
    "    \n",
    "    Parameters:\n",
    "    df: Spark DataFrame with 'value' column containing lines from WARC file\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Parsed DataFrame with columns:\n",
    "        Type, Target-URI, Date, Record-ID, Refers-To, Block-Digest,\n",
    "        Identified-Content-Language, Content-Type, Content-Length, Content\n",
    "    \"\"\"\n",
    "    from pyspark.sql.functions import monotonically_increasing_id\n",
    "    \n",
    "    # Add row number for ordering\n",
    "    df_numbered = df.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "    \n",
    "    # Identify lines that start a new WARC record\n",
    "    df_marked = df_numbered.withColumn(\n",
    "        \"is_record_start\",\n",
    "        when(col(\"value\") == \"WARC/1.0\", 1).otherwise(0)\n",
    "    )\n",
    "    \n",
    "    # Create record_id by cumulative sum\n",
    "    window_spec = Window.orderBy(\"row_id\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "    df_grouped = df_marked.withColumn(\n",
    "        \"record_id\",\n",
    "        spark_sum(\"is_record_start\").over(window_spec)\n",
    "    )\n",
    "    \n",
    "    # Group all lines belonging to same record and concatenate with newlines\n",
    "    df_records = df_grouped.groupBy(\"record_id\").agg(\n",
    "        concat_ws(\"\\n\", collect_list(\"value\")).alias(\"record_text\")\n",
    "    )\n",
    "    \n",
    "    # Filter out empty records\n",
    "    df_records = df_records.filter(col(\"record_text\") != \"\")\n",
    "    \n",
    "    # Define schema for parsed output\n",
    "    record_schema = StructType([\n",
    "        StructField('Type', StringType(), True),\n",
    "        StructField('Target-URI', StringType(), True),\n",
    "        StructField('Date', StringType(), True),\n",
    "        StructField('Record-ID', StringType(), True),\n",
    "        StructField('Refers-To', StringType(), True),\n",
    "        StructField('Block-Digest', StringType(), True),\n",
    "        StructField('Identified-Content-Language', StringType(), True),\n",
    "        StructField('Content-Type', StringType(), True),\n",
    "        StructField('Content-Length', StringType(), True),\n",
    "        StructField('Content', StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    # UDF to parse each record\n",
    "    parse_udf = udf(parse_single_wet_record, record_schema)\n",
    "    \n",
    "    # Parse records\n",
    "    df_parsed = df_records.withColumn(\"parsed\", parse_udf(col(\"record_text\")))\n",
    "    \n",
    "    # Filter out null parsed records and expand struct\n",
    "    df_final = df_parsed.filter(col(\"parsed\").isNotNull()).select(\"parsed.*\")\n",
    "\n",
    "    # Remove warcinfo records\n",
    "    df_final = df_final.filter(col(\"Type\") != \"warcinfo\")\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bf3c899-8abd-4b43-bb4d-4c5d8db5c3c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clean = convert_wet_dataframe(df)\n",
    "\n",
    "display(df_clean.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14590bf7-f5a3-409a-99a4-5d604c19eb28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clean.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0aed6bce-b06a-422d-9f8c-4287e3c7a753",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.4 Basic Filtering\n",
    "- Filters the parsed data to keep only relevant records\n",
    "- Keeps only:\n",
    "  * English-only content (no mixed languages)\n",
    "  * Websites from .com, .org, .edu, or .gov domains\n",
    "- Input: Parsed WET table\n",
    "- Output: Filtered table with only English content from specified domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3794fb7e-9285-40e1-b2a0-9f8a77bcb6b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to apply basic filtering\n",
    "def filter_wet_records(df):\n",
    "    \"\"\"\n",
    "    Filter WET records to only include:\n",
    "    - URLs with .com, .org, .edu, or .gov domains\n",
    "    - Records where Identified-Content-Language is 'eng'\n",
    "    \n",
    "    Parameters:\n",
    "    df: Parsed WET DataFrame with columns including 'Target-URI' and 'Identified-Content-Language'\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Filtered DataFrame\n",
    "    \"\"\"\n",
    "    from pyspark.sql.functions import lower, trim\n",
    "    \n",
    "    # Filter for English content\n",
    "    df_filtered = df.filter(\n",
    "        (lower(trim(col(\"Identified-Content-Language\"))) == \"eng\")\n",
    "    )\n",
    "    \n",
    "    # Filter for specific domains (.com, .org, .edu, .gov)\n",
    "    # Using regex to match domains properly (not matching .com.au, etc.)\n",
    "    df_filtered = df_filtered.filter(\n",
    "        col(\"Target-URI\").rlike(r'://[^/]*\\.(com|org|edu|gov)(/|$)')\n",
    "    )\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a95f300-926d-4a13-ae47-75062e9a13be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_filter = filter_wet_records(df_clean)\n",
    "\n",
    "display(df_filter.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e04b2978-2d4a-47ec-88c8-10a282d3b42a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_filter.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f705e89-fe95-49ce-b0bb-a01be68eea60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Keyword Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0bd5700-a50b-4f9c-9c19-e06b8b08d569",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.1 Keyword Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86a9267b-a02f-453a-adb8-07f3bf0a6140",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define product-level keywords\n",
    "keywords_product = [\n",
    "        \"u.s. census bureau\",\n",
    "        \"us census bureau\", \n",
    "        \"uscb\",\n",
    "        \"census bureau\",\n",
    "        \"census.gov\",\n",
    "        \"data.census.gov\",\n",
    "        \"factfinder.census.gov\",\n",
    "        \"american community survey\",\n",
    "    ]\n",
    "\n",
    "# Geographic Terms\n",
    "keywords_geographic = [\n",
    "  \"zip code\",\n",
    "  \"zip codes\",\n",
    "  \"census tract\",\n",
    "  \"block group\",\n",
    "  \"county\",\n",
    "  \"state\",\n",
    "  \"metropolitan area\",\n",
    "  \"city\",\n",
    "  \"radius\",\n",
    "  \"geographic area\",\n",
    "  \"location\"\n",
    "  ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1cea6ed-ba63-4f45-83ae-e615f511e28a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Subject Keywords**:\n",
    "\n",
    "The Census Bureau defines all subjects covered in the American Community Survey on their website. https://www.census.gov/programs-surveys/acs/guidance/subjects.html#descriptionaccordion-73370cfb1f-item-264b8c4d39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a07d1119-de72-4182-a91c-3c0cc1ca755d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define subject-level keywords\n",
    "keywords_subject = [\n",
    "\n",
    "    # Social Keywords\n",
    "    \"ancestry\",\n",
    "    \"citizen voting-age population\",\n",
    "    \"citizenship status\",\n",
    "    \"disability status\",\n",
    "    \"educational attainment\",\n",
    "    \"fertility\",\n",
    "    \"grandparets as caregivers\",\n",
    "    \"language spoken at home\",\n",
    "    \"marital history\",\n",
    "    \"marital status\",\n",
    "    \"migration residence 1 year ago\",\n",
    "    \"place of birth\",\n",
    "    \"school enrollment\",\n",
    "    \"undergraduate field of degree\",\n",
    "    \"veterans status\",\n",
    "    \"period of military service\",\n",
    "    \"year of entry\",\n",
    "\n",
    "    # Economic keywords\n",
    "    \"class of worker\",\n",
    "    \"commuting and place of work\",\n",
    "    \"employment status\",\n",
    "    \"food stamps\",\n",
    "    \"supplemental nutrition assistance program\",\n",
    "    \"health insurance coverage\",\n",
    "    \"income and earnings\",\n",
    "    \"income and earnings\",\n",
    "    \"industry\",\n",
    "    \"occupation\",\n",
    "    \"poverty status\",\n",
    "    \"work status last year\",\n",
    "\n",
    "    # Housing keywords\n",
    "    \"bedrooms\",\n",
    "    \"computer & internet use\",\n",
    "    \"house heating fuel\",\n",
    "    \"kitchen facilities\",\n",
    "    \"occupancy/vacancy status\",\n",
    "    \"occupants per room\",\n",
    "    \"rent\",\n",
    "    \"rooms\",\n",
    "    \"selected monthly owner costs\",\n",
    "    \"telephone service available\",\n",
    "    \"tenure (owner/renter)\"\n",
    "    \"units in structure\",\n",
    "    \"value of home\",\n",
    "    \"vehicles available\",\n",
    "    \"year householder moved in unit\",\n",
    "    \"year structure built\"\n",
    "\n",
    "    # Demographic keywords\n",
    "    \"age; sex\",\n",
    "    \"group quarters population\",\n",
    "    \"hispanic or latino origin\",\n",
    "    \"race\",\n",
    "    \"relationship to householder\",\n",
    "    \"total population\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8e72b79-d04a-4bdb-961a-57c6298874b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Flattened list of all keywords (useful for regex or filtering)\n",
    "def keyword_string(keyword_list):\n",
    "    \"\"\"Returns a text string for rlike filtering\"\"\"    \n",
    "    return '|'.join(keyword_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26be2c84-30d5-46e2-aae2-193677581dfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "keyword_string(keywords_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfa9afb2-a7fc-4e37-adf6-7a0659d19421",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.2 Subject Filtering Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bee4313-a2fe-4009-a6db-afec04ee0417",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_bottomup_1 = df_filter.filter(\n",
    "    lower(col(\"Content\")).rlike(keyword_string(keywords_subject)))\n",
    "\n",
    "print(f\"Row Count: {df_bottomup_1.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "706f4212-1fdf-4b79-a210-8294ac0972f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_bottomup_2 = df_bottomup_1.filter(\n",
    "    lower(col(\"Content\")).rlike(keyword_string(keywords_geographic)))\n",
    "\n",
    "print(f\"Row Count: {df_bottomup_2.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c6610ca-2efc-46da-a1ac-81d827c434f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_bottomup_3 = df_bottomup_2.filter(\n",
    "    lower(col(\"Content\")).rlike(keyword_string(keywords_product)))\n",
    "\n",
    "print(f\"Row Count: {df_bottomup_3.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40efeba6-a4b7-4b0b-82c5-b1ec5b085337",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_bottomup_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c19ac253-58c9-4273-9e25-05d06254897a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.3 Product Filtering Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a08a6a8-818e-46f3-b195-a3236afa2144",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_top_1 = df_filter.filter(\n",
    "    lower(col(\"Content\")).rlike(keyword_string(keywords_product)))\n",
    "\n",
    "print(f\"Row Count: {df_top_1.count()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a934e391-4b56-4157-86aa-d2bb16585a7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "time_end = time.time()\n",
    "print(f\"Elapsed time: {time_end - time_start:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "wet_file_transform_filter",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
