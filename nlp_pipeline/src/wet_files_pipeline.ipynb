{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9192951-39bb-4bee-8560-c26f120a45f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# End-to-End WET Files Pipeline\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0c211a9-e331-46ad-a732-7f637ea4b3dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87018363-4923-4e9f-9dee-a22869f57bb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\n",
    "    '/Workspace/Shared/gu_census_crawl/common_crawl/nlp_pipeline/src/wet_file_extraction_pipeline'\n",
    ")\n",
    "\n",
    "# Import all modules\n",
    "from helpers import (\n",
    "    sample_crawls, get_key_list, copy_wet_files,\n",
    "    convert_wet_dataframe, filter_by_domain, filter_by_keywords, keyword_string,\n",
    "    KEYWORDS_PRODUCT, KEYWORDS_GEOGRAPHIC, KEYWORDS_SUBJECT\n",
    ")\n",
    "from utils import get_s3_client, read_wet_crawls, list_s3_files, read_text_files\n",
    "from pyspark.sql.functions import col, row_number\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import Row\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1c10d58-7f73-4669-b188-e5b03449383b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. STEP 1: EXTRACTION - Read and Sample Crawls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6be1fda-90e2-4630-a460-781d72614b52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"STEP 1: Reading and Sampling WET Crawls\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Read WET crawls from bronze\n",
    "df_all_crawls = read_wet_crawls(spark)\n",
    "total = df_all_crawls.count()\n",
    "print(f\"Total WET crawls available: {total:,}\")\n",
    "display(df_all_crawls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3421c71b-d6ed-48c2-ba18-dc809d24012a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sample crawls by years\n",
    "years = ['2021', '2022', '2023', '2024', '2025']\n",
    "df_samples = sample_crawls(df_all_crawls, years, limit=2)\n",
    "\n",
    "if df_samples is None:\n",
    "    print(\"No samples found. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Sampled {len(df_samples)} crawls\")\n",
    "display(df_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "befe046b-dd62-46ee-8eed-a5563044d95f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. STEP 2: EXTRACTION - Save Samples to Bronze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4847151c-0f7d-461b-9bdf-26e9fc030adf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2: Saving Samples to Bronze Table\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_samples_spark = spark.createDataFrame(df_samples)\n",
    "df_samples_spark.write.mode(\"append\").saveAsTable(\n",
    "    \"census_bureau_capstone.bronze.sample_size_raw\"\n",
    ")\n",
    "print(\"Samples saved to bronze.sample_size_raw\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f789846a-6912-443a-b5ac-a0f3c3b74c6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. STEP 3: EXTRACTION - Copy WET Files from Common Crawl to Destination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5334d4a-5cb9-4a2d-8c7a-ddb48d3be3fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 3: Copying WET Files from Common Crawl\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get key list and copy files\n",
    "key_list = get_key_list(df_samples)\n",
    "s3 = get_s3_client(dbutils)\n",
    "copy_wet_files(s3, key_list, \"commoncrawl\", \"mydbxbucketpractice\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9200d104-6a09-4506-8016-8faeac95464f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. STEP 4: TRANSFORMATION - Read and Parse WET Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18ee64fa-1d8d-4580-9e0d-6fd80c2acb4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4: Reading and Parsing WET Files\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# List and read WET files\n",
    "file_paths = list_s3_files(dbutils, \"mydbxbucketpractice\", \"common_crawl/wet_files/\")\n",
    "df_raw = read_text_files(spark, file_paths)\n",
    "\n",
    "total_records_raw = df_raw.count()\n",
    "print(f\"Total records in raw data: {total_records_raw:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f063da6-0f6b-44f9-88f7-28dd4f47e56a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert to structured format\n",
    "df_clean = convert_wet_dataframe(df_raw)\n",
    "total_clean_count = df_clean.count()\n",
    "print(f\"Total records after parsing: {total_clean_count:,}\")\n",
    "display(df_clean.limit(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3223004f-531f-49dc-8d59-0fbf7e54b325",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6. STEP 5: TRANSFORMATION - Language Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14673c38-aec7-4d15-977f-3db70a095744",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 5: Language Detection\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Note: Language detection requires fasttext model\n",
    "# Uncomment and provide model_path if you have fasttext model\n",
    "from language_detection import detect_language_status_fasttext_with_fallback\n",
    "df_clean = detect_language_status_fasttext_with_fallback(\n",
    "     df_clean, text_col=\"Content\", out_col=\"lang_status\", add_bool=False\n",
    " )\n",
    "\n",
    "# For now, filter by Content-Length and add row numbers\n",
    "window_spec = Window.orderBy(\"Record-ID\")\n",
    "df_clean = (\n",
    "    df_clean\n",
    "    .withColumn(\"row_num\", row_number().over(window_spec))\n",
    "    .filter(col(\"Content-Length\").cast(\"int\") > 30)\n",
    ")\n",
    "\n",
    "# If language detection was run, filter for English only:\n",
    "# df_clean = df_clean.filter(col(\"lang_status\") == \"english_only\")\n",
    "\n",
    "total_english_records_found = df_clean.count()\n",
    "print(f\"Total records after filtering: {total_english_records_found:,}\")\n",
    "display(df_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a6e25e6-bb4f-4c43-bddc-9be6f1e76e9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 7. STEP 6: TRANSFORMATION - Filter by Domain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9d476f6-9908-419c-a47f-dd9ea147c70d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 6: Filtering by Domain (.com, .org, .edu, .gov)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_filter = filter_by_domain(df_clean)\n",
    "domain_filter_count = df_filter.count()\n",
    "print(f\"Records after domain filtering: {domain_filter_count:,}\")\n",
    "display(df_filter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a765abf-5589-4711-b934-3b840cb795c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 8. STEP 7: TRANSFORMATION - Filter by Product Keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b331b49d-102c-42e5-9846-1f058eb31ccc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 7: Filtering by Product Keywords\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_top_1 = filter_by_keywords(df_filter, KEYWORDS_PRODUCT)\n",
    "total_products_found = df_top_1.count()\n",
    "print(f\"Records matching product keywords: {total_products_found:,}\")\n",
    "display(df_top_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed006b53-e6c9-4232-91cb-618863472a92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 9. STEP 8: SAVE RESULTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae1ed7aa-a9bd-4834-be78-826e5561612a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 8: Saving Results\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save to silver layer\n",
    "df_top_1.write.mode(\"append\").saveAsTable(\n",
    "    \"census_bureau_capstone.silver.census_product_cleaned\"\n",
    ")\n",
    "print(\"Saved to silver.census_product_cleaned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f7cbb42-5463-4bbf-8b01-6ba948af683f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create summary\n",
    "summary_df = spark.createDataFrame([\n",
    "    Row(\n",
    "        total_products_found=total_products_found,\n",
    "        total_clean_count=total_clean_count,\n",
    "        total_english_records_found=total_english_records_found,\n",
    "        total_records_processed=total_records_raw\n",
    "    )\n",
    "])\n",
    "display(summary_df)\n",
    "summary_df.write.mode(\"append\").saveAsTable(\"census_bureau_capstone.gold.nlp_pipeline_summary\")\n",
    "print(\"Summary saved to gold.nlp_pipeline_summary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bab0822f-0627-4a04-9ee1-f59ae785de38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "df_check = spark.read.table(\"census_bureau_capstone.silver.census_product_cleaned\")\n",
    "total_duplicates = df_check.groupBy(\"Record-ID\").count().filter(col(\"count\") > 1).count()\n",
    "print(f\"Total duplicates in silver table: {total_duplicates}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8af1a840-0960-4d71-901f-419fe0118f5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 10. STEP 9: CLEANUP - Remove Temporary Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb5bff4b-7e30-418d-862c-73265025c85a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 9: Cleaning Up Temporary Files\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for file_path in file_paths:\n",
    "    dbutils.fs.rm(file_path)\n",
    "print(\"Temporary files removed\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PIPELINE COMPLETE!\")\n",
    "print(\"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "wet_files_pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
